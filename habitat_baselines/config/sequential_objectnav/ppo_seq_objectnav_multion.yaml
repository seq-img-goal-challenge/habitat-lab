BASE_TASK_CONFIG_PATH: "configs/tasks/sequential_objectnav_multion.yaml"
CMD_TRAILING_OPTS: []
ENV_NAME: "SequentialNavRLEnv"
SIMULATOR_GPU_ID: 0
TORCH_GPU_ID: 0
VIDEO_OPTION: []
TENSORBOARD_DIR: "out/ppo/multion/tb"
VIDEO_DIR: "out/ppo/multion/video_dir"
TEST_EPISODE_COUNT: -1
EVAL_CKPT_PATH_DIR: "out/ppo/multion/checkpoints"
NUM_ENVIRONMENTS: 4
CHECKPOINT_FOLDER: "out/ppo/multion/checkpoints"
TRAINER_NAME: "ppo"
SENSORS: ["DEPTH_SENSOR", "RGB_SENSOR"]
NUM_UPDATES: 300000
LOG_INTERVAL: 10
NUM_CHECKPOINTS: 100

EVAL:
  SPLIT: "val"

RL:
  SUCCESS_MEASURE: "seq_success"
  PROGRESS_MEASURE: "progress"
  REWARD_MEASURE: "distance_to_next_goal"
  SUCCESS_REWARD: 3.0
  PROGRESS_REWARD: 3.0
  SLACK_REWARD: -0.001

  MULTION:
    agent_type: "non-oracle"
    object_category_embedding_size: 32
    previous_action_embedding_size: 32
    use_previous_action: true
    MAPS:
      egocentric_map_size: 13 # 3 x 3
      global_map_size: 275
      global_map_depth: 32
      coordinate_min: -110.0
      coordinate_max:  110.0

  POLICY:
    name: "MultiONPolicy"

  PPO:
    # ppo params
    clip_param: 0.2
    ppo_epoch: 2
    num_mini_batch: 4
    value_loss_coef: 0.5
    entropy_coef: 0.01
    lr: 2.5e-4
    eps: 1e-5
    max_grad_norm: 0.2
    num_steps: 128
    use_gae: true
    gamma: 0.99
    tau: 0.95
    use_linear_clip_decay: true
    use_linear_lr_decay: true
    reward_window_size: 50
    use_normalized_advantage: false
    hidden_size: 768

  DDPPO:
    sync_frac: 0.6
    # The PyTorch distributed backend to use
    distrib_backend: NCCL
    # Visual encoder backbone
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    # Initialize with pretrained weights
    pretrained: False
    # Initialize just the visual encoder backbone with pretrained weights
    pretrained_encoder: False
    # Whether or not the visual encoder backbone will be trained.
    train_encoder: True
    # Whether or not to reset the critic linear layer
    reset_critic: True

    # Model parameters
    backbone: resnet50
    rnn_type: LSTM
    num_recurrent_layers: 2
